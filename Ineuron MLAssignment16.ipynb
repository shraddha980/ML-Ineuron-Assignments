{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e1bfd4",
   "metadata": {},
   "source": [
    "1. In a linear equation, what is the difference between a dependent variable and an independent variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ecc8d",
   "metadata": {},
   "source": [
    "The independent variable is the cause. Its value is independent of other variables in your study. The dependent variable is the effect. Its value depends on changes in the independent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac8d2ea",
   "metadata": {},
   "source": [
    "2. In a linear regression, define the slope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b78ce3",
   "metadata": {},
   "source": [
    "In a regression line passing through a set of data points in data sets Argument1 and Argument2, the slope is the vertical distance divided by the horizontal distance between any two points on the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a998cb88",
   "metadata": {},
   "source": [
    "3. In linear regression, what are the conditions for a positive slope?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79976fd1",
   "metadata": {},
   "source": [
    "Positive Linear Regression– If the value of the dependent variable increases with the increase of the independent variable, then the slope of the graph is positive; such Regression is said to be Positive Linear Regression. y=mx+c, where m is the slope of the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378aa94c",
   "metadata": {},
   "source": [
    "4. In linear regression, what are the conditions for a negative slope?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d78de1",
   "metadata": {},
   "source": [
    "In other words, a negative slope is one in which the variable x increases with the decrease in variable y and/or variable y increases with the decrease in variable x. In the same manner, the variable x decreases with the increase in variable y, and/or variable y decreases with the increase in variable x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed407c7",
   "metadata": {},
   "source": [
    "5. In multiple linear regression, define the number of squares due to error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e08025",
   "metadata": {},
   "source": [
    "The sum of squares is a statistical measure of variability. It indicates the dispersion of data points around the mean and how much the dependent variable deviates from the predicted values in regression analysis.\n",
    "\n",
    "We decompose variability into the sum of squares total (SST), the sum of squares regression (SSR), and the sum of squares error (SSE). The decomposition of variability helps us understand the sources of variation in our data, assess a model’s goodness of fit, and understand the relationship between variables.\n",
    "\n",
    "We define SST, SSR, and SSE below and explain what aspects of variability each measure. But first, ensure you’re not mistaking regression for correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c65018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
