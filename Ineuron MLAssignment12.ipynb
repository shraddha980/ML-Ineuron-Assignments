{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b66ce2a",
   "metadata": {},
   "source": [
    "1. What is prior probability? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3f98a",
   "metadata": {},
   "source": [
    "The prior probability is the probability assigned to an event before the arrival of some information that makes it necessary to revise the assigned probability.\n",
    "The revision of the prior is carried out using Bayes' rule.\n",
    "The new probability assigned to the event after the revision is called posterior probability.\n",
    "\n",
    "Priors in Bayesian statistics\n",
    "Prior probability is a fundamental concept in Bayesian statistics.\n",
    "\n",
    "In Bayesian inference, the following conceptual framework is used to analyze observed data and make inferences:\n",
    "\n",
    "there are several probability distributions that could have generated the data;\n",
    "\n",
    "each possible distribution is assigned a prior probability that reflects the statistician's subjective beliefs and knowledge accumulated before observing the data;\n",
    "\n",
    "the observed data is used to update the prior, by using Bayes' rule;\n",
    "\n",
    "as a result of the update, all the possible data-generating distributions are assigned posterior probabilities.\n",
    "\n",
    "Prior distribution\n",
    "In Bayesian statistics, it often happens that the set of probability distributions that could have generated the data is indexed by a parameter.\n",
    "\n",
    "The parameter is seen as a random variable and it is assigned a subjective probability distribution, which is called the prior distribution.\n",
    "\n",
    "The prior distribution is then updated, using the observed data, and a posterior distribution is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82a1b1",
   "metadata": {},
   "source": [
    "2. What is posterior probability? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732af0f",
   "metadata": {},
   "source": [
    "Posterior probability is a revised probability that takes into account new available information. For example, let there be two urns, urn A having 5 black balls and 10 red balls and urn B having 10 black balls and 5 red balls. Now if an urn is selected at random, the probability that urn A is chosen is 0.5. This is the a priori probability. If we are given an additional piece of information that a ball was drawn at random from the selected urn, and that ball was black, what is the probability that the chosen urn is urn A? Posterior probability takes into account this additional information and revises the probability downward from 0.5 to 0.333 according to Bayes´ theorem, because a black ball is more probable from urn B than urn A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6950c4",
   "metadata": {},
   "source": [
    "3. What is likelihood probability? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e11b1d",
   "metadata": {},
   "source": [
    "Probability corresponds to finding the chance of something given a sample distribution of the data, while on the other hand, Likelihood refers to finding the best distribution of the data given a particular value of some feature or some situation in the data.Likelihood is the hypothetical probability that an event that has already occurred would yield a specific outcome. The concept differs from that of a probability in that a probability refers to the occurrence of future events, while a likelihood refers to past events with known outcomes.\n",
    "\n",
    "Suppose we have a coin that is assumed to be fair. If we flip the coin one time, the probability that it will land on heads is 0.5. Now suppose we flip the coin 100 times and it only lands on heads 17 times. We would say that the likelihood that the coin is fair is quite low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10d92d",
   "metadata": {},
   "source": [
    "4. Define the concept of consistent learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3f1f8",
   "metadata": {},
   "source": [
    "A learner L using a hypothesis H and training data D is said to be a consistent learner if it always outputs a hypothesis with zero error on D whenever H contains such a hypothesis. By definition, a consistent learner must produce a hypothesis in the version space for H given D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b195357f",
   "metadata": {},
   "source": [
    "5. Write any two strengths of Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65f8286",
   "metadata": {},
   "source": [
    "Advantages of Naive Bayes Classifier \n",
    "The following are some of the benefits of the Naive Bayes classifier: \n",
    "\n",
    "It is simple and easy to implement\n",
    "It doesn’t require as much training data\n",
    "It handles both continuous and discrete data\n",
    "It is highly scalable with the number of predictors and data points\n",
    "It is fast and can be used to make real-time predictions\n",
    "It is not sensitive to irrelevant features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ee04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
