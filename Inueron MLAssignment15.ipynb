{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1424c22d",
   "metadata": {},
   "source": [
    "1. Go over the kNN model in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed63acb",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbors (KNN) algorithm is a popular machine learning technique used for classification and regression tasks. It relies on the idea that similar data points tend to have similar labels or values. During the training phase, the KNN algorithm stores the entire training dataset as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d7a83",
   "metadata": {},
   "source": [
    "2. What are the drawbacks of using the SVM model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa803e5",
   "metadata": {},
   "source": [
    "The Disadvantages of Support Vector Machine (SVM) are:\n",
    "\n",
    "Unsuitable to Large Datasets\n",
    "Large training time\n",
    "More features, more complexities\n",
    "Bad performance on high noise\n",
    "Does not determine Local optima\n",
    "We will dive into each point in depth.\n",
    "\n",
    "1) Unsuitable to Large Datasets\n",
    "Support Vector Machines creates a margin of separation between the data point to be classified.The usage of large datasets has its cons even if we use kernel trick for classification.No matter how computationally efficient is the calculation, it is suitable for small to medium size datasets, as the feature space can be very high dimensional, or even infinite dimensional. The method becomes infeasible for large datasets.For large datasets, this can still give us rich feature space representations, but with many fewer dimensions than data points. It will not support large datasets and many dimensions at the same time.\n",
    "\n",
    "2) Large training time\n",
    "Due to high computational complexities and above stated reasons even if kernel trick is used,SVM classification will be tedious as it will use a lot of processing time due to complexities in calculations. This will result large time to train the datasets itself.\n",
    "\n",
    "3) More features, more complexities\n",
    "More the features are taken into consideration, it will result in more dimensions coming into play.If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "\n",
    "4) Bad performance on high noise\n",
    "SVM does not perform very well, when the data set has more noise.When the data has noise, it contains many overlapping points,there is a problem in drawing a clear hyperplane without misclassifying.\n",
    "\n",
    "Soft margin classtification however allows misclassification to a small extent.\n",
    "But as the noise increases, the amount of datapoints overlapping and disturbances result in more misclassifications which is not ideal.\n",
    "\n",
    "5) Does not determine Local optima\n",
    "If you use gradient descent to solve the SVM optimization problem, then you'll always converge to the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ab8c9",
   "metadata": {},
   "source": [
    "3. Discuss the kNN algorithm's error rate and validation error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde0a62",
   "metadata": {},
   "source": [
    "By observing validation error rate we can interpret that At K=1, we were over fitting the boundaries. In Validation graph Error rate initially decreases and reaches a minima. After the minima point, it then increase with increasing K. This value of K where error reaches minima should be used for all predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce1fbad",
   "metadata": {},
   "source": [
    "4. Describe in depth the decision tree algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3f27b",
   "metadata": {},
   "source": [
    "A. A decision tree algorithm is a machine learning algorithm that uses a decision tree to make predictions. It follows a tree-like model of decisions and their possible consequences. The algorithm works by recursively splitting the data into subsets based on the most significant feature at each node of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3eb086",
   "metadata": {},
   "source": [
    "5.Explain advantages and disadvantages of using a decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a75cb",
   "metadata": {},
   "source": [
    "Advantages of Decision Trees. Interpretability. Less Data Preparation. Non-Parametric. Versatility. Non-Linearity.\n",
    "Disadvantages of Decision Tree. Overfitting. Feature Reduction & Data Resampling. Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c39b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
